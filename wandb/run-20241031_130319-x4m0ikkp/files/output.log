
  0%|                                                                                                                                      | 0/3750 [00:00<?, ?it/s]
  0%|                                                                                                                                      | 0/3750 [00:00<?, ?it/s]/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|                                                                                                                                      | 0/3750 [00:08<?, ?it/s]
Traceback (most recent call last):
  File "/home/clding/aditi/reversal/finetune.py", line 182, in <module>
    scaler.scale(loss).backward()
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/autograd/__init__.py", line 259, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/autograd/__init__.py", line 132, in _make_grads
    raise RuntimeError(
RuntimeError: grad can be implicitly created only for scalar outputs