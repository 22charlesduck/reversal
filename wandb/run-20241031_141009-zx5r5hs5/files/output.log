
  0%|                                                                                                                                       | 0/469 [00:00<?, ?it/s]
  0%|                                                                                                                                       | 0/469 [00:00<?, ?it/s]/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '













































































































































































































Epoch: [0/400] Loss: 1.5296 Acc: 0.05: 100%|██████████████████████████████████████████████████████████████████████████████████████| 469/469 [07:02<00:00,  1.11it/s]













































































































































































































Epoch: [1/400] Loss: 3.7050 Acc: 0.03: 100%|██████████████████████████████████████████████████████████████████████████████████████| 469/469 [06:53<00:00,  1.13it/s]













































































































































































































Epoch: [2/400] Loss: 4.1570 Acc: 0.00: 100%|██████████████████████████████████████████████████████████████████████████████████████| 469/469 [06:53<00:00,  1.13it/s]














































































































































































































Epoch: [3/400] Loss: 4.1168 Acc: 0.00: 100%|██████████████████████████████████████████████████████████████████████████████████████| 469/469 [06:53<00:00,  1.13it/s]













































































































































































































Epoch: [4/400] Loss: 4.0797 Acc: 0.00: 100%|██████████████████████████████████████████████████████████████████████████████████████| 469/469 [06:53<00:00,  1.13it/s]














































































































































































































Epoch: [5/400] Loss: 4.0527 Acc: 0.00: 100%|██████████████████████████████████████████████████████████████████████████████████████| 469/469 [06:54<00:00,  1.13it/s]














































































































































































































Epoch: [6/400] Loss: 4.0414 Acc: 0.00: 100%|██████████████████████████████████████████████████████████████████████████████████████| 469/469 [06:54<00:00,  1.13it/s]













































































































































































































  0%|                                                                                                                                        | 0/40 [00:00<?, ?it/s]
Epoch: [7/400] Loss: nan Acc: 0.00: 100%|████████████████████████████████████████████████████████████████████████████████████████▊| 468/469 [06:53<00:00,  1.18it/s]
Epoch: [7/400] Loss: nan Acc: 0.00: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 469/469 [06:54<00:00,  1.13it/s]














































































































































































































Epoch: [8/400] Loss: nan Acc: 0.00: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 469/469 [06:53<00:00,  1.13it/s]













































































































































































































Epoch: [9/400] Loss: nan Acc: 0.00: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 469/469 [06:53<00:00,  1.13it/s]





































































































































Epoch: [10/400] Loss: nan Acc: 0.00:  65%|████████████████████████████████████████████████████████▊                               | 303/469 [04:27<02:26,  1.13it/s]
Traceback (most recent call last):
  File "/home/clding/aditi/reversal/finetune.py", line 179, in <module>
    logits, loss, accs = model(x, y)
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 184, in forward
    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 189, in replicate
    return replicate(module, device_ids, not torch.is_grad_enabled())
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/nn/parallel/replicate.py", line 110, in replicate
    param_copies = _broadcast_coalesced_reshape(params, devices, detach)
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/nn/parallel/replicate.py", line 83, in _broadcast_coalesced_reshape
    tensor_copies = Broadcast.apply(devices, *tensors)
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/autograd/function.py", line 553, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/nn/parallel/_functions.py", line 23, in forward
    outputs = comm.broadcast_coalesced(inputs, ctx.target_gpus)
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/nn/parallel/comm.py", line 57, in broadcast_coalesced
    return torch._C._broadcast_coalesced(tensors, devices, buffer_size)
KeyboardInterrupt