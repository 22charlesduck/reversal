


Epoch: [0/5000] Loss: 5.8671 Acc: 0.00:   0%|                                                                                    | 3/3750 [00:09<3:26:36,  3.31s/it]
Traceback (most recent call last):
  File "/home/clding/aditi/reversal/finetune.py", line 174, in <module>
    scaler.step(optimizer)
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py", line 378, in step
    return optimizer.step(*args, **kwargs)
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/optim/optimizer.py", line 385, in wrapper
    out = func(*args, **kwargs)
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/optim/adamw.py", line 187, in step
    adamw(
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/optim/adamw.py", line 339, in adamw
    func(
  File "/home/clding/miniconda3/envs/reversal/lib/python3.10/site-packages/torch/optim/adamw.py", line 470, in _single_tensor_adamw
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
KeyboardInterrupt